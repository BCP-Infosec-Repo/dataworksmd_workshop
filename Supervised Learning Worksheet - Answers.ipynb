{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/GTK_Logo_Social Icon.jpg\" align=\"left\" height=125, width=125  style=\"margin:0px 15px\"/> \n",
    "<img src=\"img/dataworks.jpeg\" align=\"right\" height=125, width=125  style=\"margin:0px 15px\"/> \n",
    "\n",
    "# Supervised Learning Worksheet - Answers\n",
    "This worksheet covers concepts relating to tuning a classifier.  For this example, we will be using the problem of identifying domains generated by Domain Generating Algorithms (DGA).  \n",
    "\n",
    "Please raise your hand if you get stuck.  \n",
    "\n",
    "## Import the Libraries\n",
    "For this exercise, we will be using:\n",
    "* Pandas (http://pandas.pydata.org/pandas-docs/stable/)\n",
    "* Numpy (https://docs.scipy.org/doc/numpy/reference/)\n",
    "* Matplotlib (http://matplotlib.org/api/pyplot_api.html)\n",
    "* Scikit-learn (http://scikit-learn.org/stable/documentation.html)\n",
    "* YellowBrick (http://www.scikit-yb.org/en/latest/)\n",
    "* Seaborn (https://seaborn.pydata.org)\n",
    "* Lime (https://github.com/marcotcr/lime)\n",
    "* TPOT (https://epistasislab.github.io/tpot/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T18:06:05.581579Z",
     "start_time": "2020-01-21T18:06:05.573300Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load Libraries - Make sure to run this cell!\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import scikitplot as skplt\n",
    "from scipy.stats import uniform as sp_rand\n",
    "from yellowbrick.classifier import ClassificationReport\n",
    "from yellowbrick.classifier import ConfusionMatrix\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import lime\n",
    "from tpot import TPOTClassifier\n",
    "import joblib\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Data\n",
    "For this exercise, we are going to focus on building a pipeline and then tuning the resultant model, so we're going to use a simple model with only five features.\n",
    "\n",
    "This workshop did not cover feature extraction and engineering, so we will just make your life easy and give you the data.  The features are:\n",
    "* `length`: The character length of the domain.\n",
    "* `digits`: The number of digits in the domain.\n",
    "* `entropy`: The Shannon-entropy of the domain. (https://en.wikipedia.org/wiki/Entropy_(information_theory))\n",
    "* `vowel-cons`: The ratio of vowels to consonants.\n",
    "* `firstDigitIndex`:  The index of the first digit in the domain.  Defaults to zero if no digits are present\n",
    "* `ngrams`: The normalized sum of 2-grams, 3-grams and 4-grams present in the domain.\n",
    "\n",
    "This data set has 1000 of each class which is contained in the column `isDGA`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T17:47:27.829268Z",
     "start_time": "2020-01-21T17:47:27.813969Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>digits</th>\n",
       "      <th>entropy</th>\n",
       "      <th>vowel-cons</th>\n",
       "      <th>firstDigitIndex</th>\n",
       "      <th>ngrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.398590</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0</td>\n",
       "      <td>900.265657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.404863</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0</td>\n",
       "      <td>1249.554390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.315205</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0</td>\n",
       "      <td>1810.704762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1284</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0.431853</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0</td>\n",
       "      <td>1724.440768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0.421695</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>873.297070</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      length  digits   entropy  vowel-cons  firstDigitIndex       ngrams\n",
       "647       12       0  0.398590    0.200000                0   900.265657\n",
       "1577      13       0  0.404863    0.625000                0  1249.554390\n",
       "1031       7       0  0.315205    0.750000                0  1810.704762\n",
       "1284      17       0  0.431853    0.888889                0  1724.440768\n",
       "467       15       0  0.421695    0.250000                0   873.297070"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final = pd.read_csv('data/dga_features_final_df.csv')\n",
    "target = df_final['isDGA']\n",
    "feature_matrix = df_final.drop(['isDGA'], axis=1)\n",
    "feature_matrix.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into training and testing sets.\n",
    "Next, we're going to need a training and testing dataset, so you know the drill, split the data.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T17:47:28.396363Z",
     "start_time": "2020-01-21T17:47:28.392100Z"
    }
   },
   "outputs": [],
   "source": [
    "# Simple Cross-Validation: Split the data set into training and test data\n",
    "feature_matrix_train, feature_matrix_test, target_train, target_test = train_test_split(feature_matrix, \n",
    "                                                                                        target, \n",
    "                                                                                        test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Model\n",
    "For this exercise, we're going to create a K-NN Classifier for the DGA data and tune it, but first, create a classifier with the default options and calculate the accuracy score for it. (http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) \n",
    "\n",
    "The default parameters are shown below.\n",
    "```python \n",
    "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
    "           weights='uniform')\n",
    "```           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T17:47:29.220463Z",
     "start_time": "2020-01-21T17:47:29.213766Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here ...\n",
    "clf = KNeighborsClassifier()\n",
    "clf.fit( feature_matrix_train, target_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T17:47:29.623006Z",
     "start_time": "2020-01-21T17:47:29.606016Z"
    }
   },
   "outputs": [],
   "source": [
    "#Store the predictions\n",
    "default_predictions = clf.predict( feature_matrix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T17:47:30.017018Z",
     "start_time": "2020-01-21T17:47:30.012816Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.836"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score( target_test, default_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving Performance \n",
    "Out of the box, the model achieves approximately 85% accuracy.  Better than chance but let's see if we can do better. \n",
    "\n",
    "**Note:  This notebook is written without using fixed random seeds, so you might get slightly different results.**\n",
    "\n",
    "### Scaling the Features\n",
    "K-NN is a distance-based classifier and hence it is necessary to scale the features prior to training the model.  For this exercise however, let's create a simple pipeline with two steps:\n",
    "\n",
    "1.  StandardScaler\n",
    "2.  Train the classifier\n",
    "\n",
    "Pipelines are objects which can encapsulate multiple steps in the ML process.  Here is a link to the documentation (https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) and a brief tutorial about pipelines: (https://towardsdatascience.com/a-simple-example-of-pipeline-in-machine-learning-with-scikit-learn-e726ffbb6976)\n",
    "\n",
    "Once you've done that, calculate the accuracy and see if it has improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T17:47:30.823671Z",
     "start_time": "2020-01-21T17:47:30.821263Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create the pipeline here\n",
    "pipeline = Pipeline([\n",
    "    ('scaler',StandardScaler()),\n",
    "    ('clf', KNeighborsClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T17:47:31.249805Z",
     "start_time": "2020-01-21T17:47:31.237910Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('scaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('clf',\n",
       "                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
       "                                      metric='minkowski', metric_params=None,\n",
       "                                      n_jobs=None, n_neighbors=5, p=2,\n",
       "                                      weights='uniform'))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now fit the pipeline as you would a regular model\n",
    "pipeline.fit(feature_matrix_train, target_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T17:47:31.774238Z",
     "start_time": "2020-01-21T17:47:31.754491Z"
    }
   },
   "outputs": [],
   "source": [
    "#  Next, make predictions using the pipeline object\n",
    "pipeline_predictions = pipeline.predict( feature_matrix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T17:47:32.199237Z",
     "start_time": "2020-01-21T17:47:32.195071Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.886"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And... calculate the accuracy_score by comparing the target_test with the predictions from the pipeline\n",
    "accuracy_score( target_test, pipeline_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling the features did result in a small improvement: .85 accuracy to .88.  But let's see if we can't do even better.\n",
    "\n",
    "### Using RandomSearchCV and GridSearchCV to tune Hyperparameters\n",
    "Now that we've scaled the features and built a simple pipeline, let's try to tune the hyperparameters to see if we can improve the model performance.  Scikit-learn provides two methods for accomplishing this task: `RandomizedSearchCV` and `GridSearchCV`. \n",
    "\n",
    "\n",
    "* `GridSearchCV`:  GridSearch iterates through all possible combinations of tuning parameters to find the optimal combination. (http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)\n",
    "* `RandomizedSearchCV`:  RandomizedSearch interates through random combinations of paremeters to find the optimal combination.  While RandomizedSearch does not try every possible combination, is considerably faster than GridSearch and has been shown to get very close to the optimal combination in considerably less time.  (http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html) \n",
    "\n",
    "You can see in the results below, that the model was able to achieve **91.9%** accuracy with RandomSearch!   \n",
    "```\n",
    "[INFO] randomized search took 0.85 seconds\n",
    "[INFO] grid search accuracy: 91.93%\n",
    "[INFO] randomized search best parameters: {'clf__weights': 'uniform', 'clf__p': 1, 'clf__n_neighbors': 27, 'clf__metric': 'euclidean', 'clf__leaf_size': 25, 'clf__algorithm': 'kd_tree'}\n",
    "```\n",
    "\n",
    "Both `RandomizedSearchCV` and `GridSearchCV` require you to provide a grid of parameters.  You will need to refer to the documentation for the classifier you are using to get a list of paramenters for that particular model.  Also since we will be using the pipeline, you have to format the parameters correctly.  The name of the variable must be preceeded by the name of the step in your pipeline and two underscores.  For example.  If the classifier in the pipeline is called `clf`, and you have a tuning parameter called `metric`, the parameter grid would be as follows:\n",
    "```python\n",
    "params = {\n",
    "    \"clf__n_neighbors\": np.arange(1, 50, 2),\n",
    "    \"clf__metric\": [\"euclidean\", \"cityblock\"] \n",
    "}\n",
    "```\n",
    "\n",
    "### Your Task\n",
    "Using either GridSearchCV or RandomizedSearchCV, improve the performance of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T17:47:40.622127Z",
     "start_time": "2020-01-21T17:47:33.723033Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] randomized search took 6.89 seconds\n",
      "[INFO] grid search accuracy: 91.07%\n",
      "[INFO] randomized search best parameters: {'clf__weights': 'uniform', 'clf__p': 1, 'clf__n_neighbors': 29, 'clf__metric': 'euclidean', 'clf__leaf_size': 15, 'clf__algorithm': 'auto'}\n"
     ]
    }
   ],
   "source": [
    "params = {\"clf__n_neighbors\": np.arange(1, 50, 2), \n",
    "         \"clf__weights\": [\"uniform\", \"distance\"],\n",
    "         \"clf__algorithm\": ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "         \"clf__leaf_size\": np.arange(1, 80, 2),\n",
    "         \"clf__p\": [1,2],\n",
    "         \"clf__metric\": [\"euclidean\", \"manhattan\"]}\n",
    "\n",
    "\n",
    "\n",
    "grid = RandomizedSearchCV(pipeline, params, n_iter=100)\n",
    "start = time.time()\n",
    "grid.fit(feature_matrix_train, target_train)\n",
    " \n",
    "# evaluate the best randomized searched model on the testing\n",
    "# data\n",
    "print(\"[INFO] randomized search took {:.2f} seconds\".format(time.time() - start))\n",
    "\n",
    "#acc = grid.score(feature_matrix_test, target_test)\n",
    "acc = grid.best_score_\n",
    "print(\"[INFO] grid search accuracy: {:.2f}%\".format(acc * 100))\n",
    "print(\"[INFO] randomized search best parameters: {}\".format(grid.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparison\n",
    "Your final task is to:\n",
    "1.  Using RandomForest, create a classifier for the DGA dataset\n",
    "2.  Use either GridSearchCV or RandomizedSearchCV to find the optimal parameters for this model.\n",
    "\n",
    "How does this model compare with the first K-NN classifier for this data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T17:47:51.330582Z",
     "start_time": "2020-01-21T17:47:40.839544Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] randomized search took 10.49 seconds\n",
      "[INFO] grid search accuracy: 90.93%\n",
      "[INFO] randomized search best parameters: {'n_estimators': 351, 'max_features': 'auto', 'max_depth': 3, 'criterion': 'entropy'}\n"
     ]
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier()\n",
    "params = {\n",
    "    \"n_estimators\": np.arange(1, 400, 50),\n",
    "    \"max_features\": ['auto', 'sqrt','log2' ],\n",
    "    \"max_depth\": np.arange(1, 20, 2),\n",
    "    \"criterion\": ['gini','entropy']\n",
    "} \n",
    "\n",
    "rf_grid = RandomizedSearchCV(rf_clf, params )\n",
    "start = time.time()\n",
    "rf_grid.fit(feature_matrix_train, target_train)\n",
    " \n",
    "# evaluate the best randomized searched model on the testing\n",
    "# data\n",
    "print(\"[INFO] randomized search took {:.2f} seconds\".format(time.time() - start))\n",
    "\n",
    "#acc = grid.score(feature_matrix_test, target_test)\n",
    "acc = rf_grid.best_score_\n",
    "print(\"[INFO] grid search accuracy: {:.2f}%\".format(acc * 100))\n",
    "print(\"[INFO] randomized search best parameters: {}\".format(rf_grid.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automate Everything with TPOT \n",
    "In the final step, you will use TPOT to create a classification pipeline using the DGA data set that we have been using.  The `TPOTClassifier()` has many configuration options and in the interest of time, please set the following variables when you instantiate the classifier.\n",
    "\n",
    "* `max_time_mins`:  In the interests of time, set this to 15 or 20.\n",
    "* `verbosity`: Set to 1 or 2 so you can see what TPOT is doing.\n",
    "\n",
    "\n",
    "**Note:  This step will take some time, so you might want to get some coffee or a snack when it is running.**  While this is running take a look at the other configuration options available here: http://epistasislab.github.io/tpot/api/.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T17:54:57.675007Z",
     "start_time": "2020-01-21T17:49:56.640864Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: xgboost.XGBClassifier is not available and will not be used by TPOT.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0d3908b69b746538c52469ef8cc5310",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Optimization Progress', style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current best internal CV score: 0.9173333333333333\n",
      "Generation 2 - Current best internal CV score: 0.9179999999999999\n",
      "Generation 3 - Current best internal CV score: 0.9179999999999999\n",
      "Generation 4 - Current best internal CV score: 0.9200000000000002\n",
      "Generation 5 - Current best internal CV score: 0.9200000000000002\n",
      "Generation 6 - Current best internal CV score: 0.9200000000000002\n",
      "Generation 7 - Current best internal CV score: 0.9200000000000002\n",
      "Generation 8 - Current best internal CV score: 0.9200000000000002\n",
      "\n",
      "5.01 minutes have elapsed. TPOT will close down.\n",
      "TPOT closed during evaluation in one generation.\n",
      "WARNING: TPOT may not provide a good pipeline if TPOT is stopped/interrupted in a early generation.\n",
      "\n",
      "\n",
      "TPOT closed prematurely. Will use the current best pipeline.\n",
      "\n",
      "Best pipeline: ExtraTreesClassifier(input_matrix, bootstrap=True, criterion=entropy, max_features=0.55, min_samples_leaf=3, min_samples_split=2, n_estimators=100)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TPOTClassifier(config_dict=None, crossover_rate=0.1, cv=5,\n",
       "               disable_update_check=False, early_stop=None, generations=100,\n",
       "               max_eval_time_mins=5, max_time_mins=5, memory=None,\n",
       "               mutation_rate=0.9, n_jobs=-1, offspring_size=None,\n",
       "               periodic_checkpoint_folder=None, population_size=100,\n",
       "               random_state=None, scoring=None, subsample=1.0, template=None,\n",
       "               use_dask=False, verbosity=2, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here... \n",
    "optimizer = TPOTClassifier(n_jobs=-1, verbosity=2, max_time_mins=5)\n",
    "optimizer.fit(feature_matrix_train, target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T16:47:27.810498Z",
     "start_time": "2020-01-21T16:47:27.803573Z"
    }
   },
   "source": [
    "## Step Three:  Evaluate the Performance\n",
    "Now that you have a trained model, the next step is to evaluate the performance and see how TPOT did in comparison with earlier models we created.  Use the techniques you've learned to evaluate the performance of your model.  Specifically, print out the `classification report` and a confusion matrix. \n",
    "\n",
    "Unfortunately, Yellowbrick will not work in this instance, however, you can generate a similar visual confusion matrix with the following code:\n",
    "\n",
    "```\n",
    "import scikitplot as skplt\n",
    "skplt.metrics.confusion_matrix(optimized_preds, target_test)\n",
    "\n",
    "```\n",
    "\n",
    "What is the accuracy of your model?  Is it significantly better than what you did in earlier labs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T17:59:49.673882Z",
     "start_time": "2020-01-21T17:59:49.655956Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions = optimizer.predict(feature_matrix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T17:59:50.742969Z",
     "start_time": "2020-01-21T17:59:50.735193Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.85      0.90       278\n",
      "           1       0.83      0.96      0.89       222\n",
      "\n",
      "    accuracy                           0.90       500\n",
      "   macro avg       0.90      0.90      0.90       500\n",
      "weighted avg       0.90      0.90      0.90       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(predictions, target_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T18:00:10.096617Z",
     "start_time": "2020-01-21T18:00:09.523902Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fbb110734d0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "skplt.metrics.plot_confusion_matrix(predictions, target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
